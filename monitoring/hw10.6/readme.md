# Задание

Постмортем, на основе реального сбоя системы Github в 2018 году.


<table>
	<tr> 
	    <td colspan="2">Краткое описание инцидента</td>
	    <td>Несколько сервисов GitHub пострадали от нарушения связности сети и последующих проблем в работе БД. В результате множество пользователей наблюдали устаревшую или неполную информацию на сайте GitHub.com. В период восстановления хостинга в работу, команде проекта пришлось остановить работу веб-хуков, что так же могло доставлять пользователям неудобства.</td>
	</tr>
	<tr>
	    <td colspan="2">Предшествующие события</td>
	    <td>Техобслуживание сети для замены оборудования.</td>
	</tr>
	<tr>
	    <td colspan="2">Причина инцидента </td>
	    <td>Потеря соединения в оптическом канале связи. Что привело к рассогласованности кластеров MySQL.</td>
	</tr>
	<tr>
	    <td colspan="2">Воздействие</td>
	    <td>В течение 24 часов и 11 минут 100% пользователей испытывали проблемы при работе с сайтом: не работали Issues, Webhooks, невозможно было создать и разместить странички на GitHub Pages, на сайте отображалась устаревшая или неполная информация.</td>
	</tr>
	<tr>
        <td colspan="2">Обнаружение</td>
	    <td>Обнаружено инженерами, которые среагировали на сообщения мониторинга.</td>
	</tr>
	<tr>
	    <td colspan="2">Реакция</td>
	    <td>Подключили дополнительных инженеров из команды администрирования БД. Отключили часть сервисов для пользователей, чтобы снизить нагрузку на кластер и обезопасить систему от дальнейшей потери пользовательских данных.</td>
	</tr>
	<tr>
	    <td colspan="2">Восстановление</td>
	    <td>Инженеры разработали план по восстановлению основного кластера на восточном побережье из резервной копии и последующей репликации актуальных данных с кластера на западном побережье. В середине следующего рабочего дня, когда нагрузка на сервис стала пиковой, были развёрнуты дополнительные кластеры БД. На последнем этапе были возвращены в работу отключенные сервисы, и скопившиеся в беклоге задачи по вызову веб-хуков и публикации GitHub Pages начали выполняться, это заняло более 6 часов.</td>
	</tr>
	<tr>
	    <td rowspan="13">Таймлайн</td>
	    <td>2018.10.21 22:52</td>
        <td>Развалился кластер БД, после восстановления связи в двух частях кластера оказались разрозненные данные</td>
	</tr>
    <tr> 
	    <td>2018.10.21 22:54</td>
        <td>Система мониторинга начала посылать сообщения об ошибках</td>
	</tr>
    <tr> 
	    <td>2018.10.21 23:13</td>
        <td>Проблема затронула несколько кластеров баз данных. Были вызваны дополнительные инженеры из группы разработки баз данных GitHub. Они начали исследовать текущее состояние.</td>
	</tr>
    <tr> 
	    <td>2018.10.21 23:19</td>
        <td>Выбрана стратегия ухудшить удобство использования сайта, приостановив доставку веб-перехватчика и сборки GitHub Pages вместо того, чтобы не подвергать опасности целостность данных.</td>
	</tr>
    <tr> 
	    <td>2018.10.22 00:05</td>
        <td>Инженеры начали разработку плана по возврату кластера БД к консистентному состоянию, основная сложность была в объёме данных.</td>
	</tr>
    <tr> 
	    <td>2018.10.22 00:41</td>
        <td>начался процесс восстановления из бекапа.</td>
	</tr>
    <tr> 
	    <td>2018.10.22 06:51</td>
        <td>Несколько кластеров завершили восстановление из бекапов в датацентре на восточном побережье и начали репликацию данных с дата центра на западном побережье</td>
	</tr>
    <tr> 
	    <td>2018.10.22 07:46</td>
        <td>GutHub опубликовали пост в блоге, чтобы донести пользователям больше информации.</td>
	</tr>
    <tr> 
	    <td>2018.10.22 11:12</td>
        <td>Восстановлены сервера в US East Coast, продолжается реплицирование. налюдается повышенная нагрузка при реплицировании.</td>
	</tr>
    <tr> 
	    <td>2018.10.22 13:15</td>
        <td>Приближались к пиковому периоду нагрузок. Увеличили количество репликаций для снятия растущей нагрузки по реплицированию.</td>
	</tr>
    <tr> 
	    <td>2018.10.22 16:24</td>
        <td>Синхронизация реплик завершилась, инициирован возврат к исходной топологии</td>
	</tr>
    <tr> 
	    <td>2018.10.22 16:46</td>
        <td>После восстановления возникла необходимость балансировки нагрузки для восстановления 100% услуг клиентам</td>
	</tr>
    <tr> 
	    <td>2018.10.22 16:03</td>
        <td>Все ожидающие сборки веб-хуков и страниц были обработаны, и была подтверждена целостность и правильная работа всех систем.</td>
	</tr>
	<tr>
	    <td colspan="2">Последующие действия</td>
	    <td>Настроить конфигурацию Orchestrator, чтобы предотвратить продвижение основных баз данных через региональные границы.
            <br>
            <br>
            Изменить систему отчетности для получения данных более понятным языком 
            <br>
            <br>
            За несколько недель до этого инцидента начали общекорпоративную инженерную инициативу целью этого проекта является поддержка резервирования N+1 на уровне объекта. Цель этой работы — допустить полный отказ одного центра обработки данных без воздействия на пользователя. 
            <br>
            <br>
            Компания будет инвестировать больше в chaos engineering, тестируя различные сценарии отказа.
            <br>
            <br>
            Так же запланирован ряд других инициатив для повышения эффективности работы системы и снижения риска потери работоспособности системы
        </td>
	</tr>

</table>|